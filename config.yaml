# MCP Configuration
ollama:
  host: http://localhost
  port: 11434

models:
  title_model: llama3.2:1b-instruct-q4_K_M
  description_model: qwen2:1.5b
  provider: ollama
  temperature: 0.4
  max_output_tokens: 512
  concurrency: 1  # keep low for limited RAM
  batch_size: 10
  timeout: 150
  quantize: false

quantized_models:
  llama3.2:1b-instruct-q4_K_M: llama3.2:1b-instruct-q2_K
  gemma3:1b-it-qat: gemma3:1b-it-q2_K
  qwen2:1.5b: qwen2:0.5b

paths:
  database: postgresql://mcp_user:mcp_password@localhost:5432/mcp_db
  log_table: changes_log
  prompt_dir: ./data/prompts

fields:
  process:
    - title
    - body_html
    - tags
    - category

categories:
  taxonomy_source: google_merchant_center
  taxonomy_url: https://www.google.com/basepages/producttype/taxonomy.en-US.txt

pipeline:
  steps:
    - extract
    - clean
    - enrich
    - validate
    - review_queue

workers:
  max_workers: 4
  queue_size: 100
  timeout: 300
  retry_attempts: 3
  batch_size: 10

postgres:
  host: postgres
  port: 5432
  user: mcp_user
  password: mcp_password
  database: mcp_db

model_capabilities:
  capabilities:
    llama3.2:1b-instruct-q4_K_M:
      tasks:
        - meta_optimization
        - keyword_analysis
        - tag_optimization
      description: Fast meta tags, keyword analysis, and tag optimization
      max_tokens: 512
    gemma3:1b-it-qat:
      tasks:
        - content_rewriting
        - meta_optimization
      description: Content rewriting and SEO optimization
      max_tokens: 1024
    qwen2:1.5b:
      tasks:
        - schema_analysis
        - keyword_analysis
      description: Schema analysis and complex keyword tasks
      max_tokens: 2048
  fallback_order:
    - qwen2:1.5b
    - gemma3:1b-it-qat
    - llama3.2:1b-instruct-q4_K_M
